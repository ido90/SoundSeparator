{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Separator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads N audio signals which are mixed recordings of M=N audio sources, synchronizes their beginnings, and tries to reconstruct the original source signals using ICA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**: paths of WAV files (see \"files\" variable below). Files can be converted to WAV online, e.g. [here](https://audio.online-convert.com/convert-to-wav)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline audio player**: to enable inline audio player, notebook should be opened using:\n",
    "\n",
    "    jupyter notebook --NotebookApp.iopub_data_rate_limit=30000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "from time import time\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "from pprint import pprint\n",
    "import os, sys\n",
    "from warnings import warn\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = Path('Data/Recordings_1')\n",
    "files = ('Galaxy_S8_20190614112028','Mi_A2_20190614110933','Redmi_note_20190614110921')\n",
    "layout_sources = ('Recordings_layout_marked.jpg', 'Recordings_layout.jpg')\n",
    "\n",
    "INLINE_PLAYER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(files)\n",
    "T0 = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_found = False\n",
    "for ls in layout_sources:\n",
    "    if os.path.isfile(DATA/ls):\n",
    "        plt.figure(figsize=(16,10))\n",
    "        plt.imshow(np.asarray(Image.open(DATA/ls)))\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        break\n",
    "\n",
    "if not source_found:\n",
    "    print('Layout image unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Show Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read audio files\n",
    "signals = {}\n",
    "for file in files:\n",
    "    nm = file[:-15]\n",
    "    y, sr = librosa.load(DATA/(file+'.wav'))\n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    signals[nm] = {'y':y, 'sr':sr, 'tempo':tempo, 'beat_frames':beat_frames}\n",
    "    print(f'{nm:s}:\\tlen = {len(y):d};\\tsample_rate = {sr:f};\\tbeats per minute = {tempo:.2f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show raw signals\n",
    "\n",
    "_, axs = plt.subplots(N,2, figsize=(16,4*N))\n",
    "\n",
    "for i,sig in enumerate(signals):\n",
    "    y = signals[sig]['y']\n",
    "    \n",
    "    ax = axs[i,0]\n",
    "    t = range(0,len(y),len(y)//500)\n",
    "    ax.plot(np.array(list(t))/sr, y[t])\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_ylabel('Signal')\n",
    "    ax.set_title(f'[Full] {sig:s}')\n",
    "    ax.grid()\n",
    "    \n",
    "    ax = axs[i,1]\n",
    "    t = range(len(y)//2-500,len(y)//2+500)\n",
    "    ax.plot(np.array(list(t))/sr, y[t])\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_ylabel('Signal')\n",
    "    ax.set_title(f'[Zoom In] {sig:s}')\n",
    "    ax.grid()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if INLINE_PLAYER:\n",
    "    file = files[0]\n",
    "    print(file)\n",
    "player = ipd.Audio(str(DATA/(file+'.wav'))) if INLINE_PLAYER else None\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if INLINE_PLAYER:\n",
    "    file = files[1]\n",
    "    print(file)\n",
    "player = ipd.Audio(str(DATA/(file+'.wav'))) if INLINE_PLAYER else None\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if INLINE_PLAYER:\n",
    "    file = files[2]\n",
    "    print(file)\n",
    "player = ipd.Audio(str(DATA/(file+'.wav'))) if INLINE_PLAYER else None\n",
    "player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = [signals[sig]['y'] for sig in signals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift_max = sr * 30\n",
    "shift_step = 10\n",
    "mask_len = sr * 30\n",
    "mask_base = sr * 120\n",
    "\n",
    "def corr(i, j, shift):\n",
    "    # certainly can be done more elegantly; however, naively using np.corrcoef()[0,1] or np.convolve() was very slow.\n",
    "    yi = Y[i][mask_base+max(0,-shift) : mask_base+max(0,-shift)+mask_len]\n",
    "    yj = Y[j][mask_base+max(0, shift) : mask_base+max(0, shift)+mask_len]\n",
    "    return np.correlate(yi,yj) / np.sqrt(np.matmul(yi,yi)*np.matmul(yj,yj))\n",
    "\n",
    "_, axs = plt.subplots(1,N, figsize=(16,4))\n",
    "\n",
    "shifts = range(-shift_max, shift_max, shift_step)\n",
    "i = 0\n",
    "cnvs = []\n",
    "for j in tnrange(N):\n",
    "    cnvs.append([corr(i,j,shift) for shift in shifts])\n",
    "    ax = axs[j]\n",
    "    ax.plot(np.array(list(shifts))/sr, cnvs[-1])\n",
    "    ax.set_xlabel('Shift [s]')\n",
    "    ax.set_ylabel('Corr')\n",
    "    ax.set_title(f'{i:d} / {j:d}')\n",
    "    ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "offsets = [shifts[np.argmax(cnv)] for cnv in cnvs]\n",
    "print('Sync offsets [s]:')\n",
    "print([np.round(off/sr,2) for off in offsets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = sr * 80\n",
    "Ysync = [y[start+off:] for y,off in zip(Y,offsets)]\n",
    "length = np.min([len(y) for y in Ysync])\n",
    "Ysync = [y[:length] for y in Ysync]\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show synced signals\n",
    "\n",
    "_, axs = plt.subplots(N,2, figsize=(16,4*N))\n",
    "\n",
    "for i,(y,sig) in enumerate(zip(Ysync,signals)):\n",
    "    ax = axs[i,0]\n",
    "    t = range(0,len(y),len(y)//500)\n",
    "    ax.plot(np.array(list(t))/sr, y[t])\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_ylabel('Signal')\n",
    "    ax.set_title(f'[Full] {sig:s}')\n",
    "    ax.grid()\n",
    "    \n",
    "    ax = axs[i,1]\n",
    "    t = range(len(y)//2-500,len(y)//2+500)\n",
    "    ax.plot(np.array(list(t))/sr, y[t])\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_ylabel('Signal')\n",
    "    ax.set_title(f'[Zoom In] {sig:s}')\n",
    "    ax.grid()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file, y in zip(files,Ysync):\n",
    "    librosa.output.write_wav(DATA/(file+'_synced'+'.wav'), y, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.c_[Ysync].transpose()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ica = FastICA(n_components=N)\n",
    "S = ica.fit_transform(X)\n",
    "ica_transformation = ica.mixing_\n",
    "\n",
    "print(S.shape)\n",
    "print(ica_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show separated signals\n",
    "\n",
    "_, axs = plt.subplots(N,2, figsize=(16,4*N))\n",
    "\n",
    "for i,sig in enumerate(('Comp 1','Comp 2','Comp 3')):\n",
    "    y = S[:,i]\n",
    "    \n",
    "    ax = axs[i,0]\n",
    "    t = range(0,len(y),len(y)//500)\n",
    "    ax.plot(np.array(list(t))/sr, y[t])\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_ylabel('Signal')\n",
    "    ax.set_title(f'[Full] {sig:s}')\n",
    "    ax.grid()\n",
    "    \n",
    "    ax = axs[i,1]\n",
    "    t = range(len(y)//2-500,len(y)//2+500)\n",
    "    ax.plot(np.array(list(t))/sr, y[t])\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_ylabel('Signal')\n",
    "    ax.set_title(f'[Zoom In] {sig:s}')\n",
    "    ax.grid()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    y = np.array(100*S[:,i], dtype=np.float32)\n",
    "    librosa.output.write_wav(DATA/f'Comp_{i:d}.wav', y, sr, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player = ipd.Audio(str(DATA/f'Comp_{0:d}.wav')) if INLINE_PLAYER else None\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player = ipd.Audio(str(DATA/f'Comp_{1:d}.wav')) if INLINE_PLAYER else None\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player = ipd.Audio(str(DATA/f'Comp_{2:d}.wav')) if INLINE_PLAYER else None\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f'Total running time:\\t{time()-T0}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
